---
title: 如何通俗的解释chatGPT的原理
date: 2023-03-01 23:49:58
permalink: /pages/acfe0c/
categories:
  - 算法与数据结构
tags:
  - 
---
![](https://gcy-1306312261.cos.ap-chengdu.myqcloud.com/blog/20230302100049.png)

类似 GPT 这种大型的语言模型，它本质上就是在那计算

<font color=#dd0000 size=4>下一个词 下一句话 该出现什么</font>

就是个概率问题，就比如说它说到了

> 我很

要往下接，那数据库里那么多词儿，可以是我很开心、我很健康、我很着急 我很饿等等

但是你要有个上下文，比如上面说

> 今天天气不错

那它可能就计算出来说大概率就是

> 我很开心

其实它的每个回答 每个词儿，都是这么简单粗暴

靠 <font color=#dd0000 size=4>前文的相关性来计算出来</font>

![](https://gcy-1306312261.cos.ap-chengdu.myqcloud.com/blog/20230302101043.png)

当它学习内容足够多，就上千亿的参数和文字，通过这些复杂模型找规律之后，它自己就形成了一个

非常庞大的 <font color=#dd0000 size=4>神经网络</font>

就你完全不需要告诉它，什么叫编程、什么是视频脚本， 它自己看多了它就知道了，编程就是这么写代码，视频脚本就该长这样。<font color=#dd0000 size=4>这个语言模型就是在学别人说话</font>

那它知道，它自己说的是什么意思吗

至少目前这个 ChatGPT 的版本

<font color=#dd0000 size=4>它还完全不懂，它就像是个记忆力特别好，但是什么都不太懂的小孩，在那学大人说话 </font>

但是让我们以为，它好像什么都懂了，这也是为什么，就你看它说的那个话，真的都已经非常完美，非常像人类了

但是还经常会犯一些，逻辑性的错误，看着觉得非常弱智，就加减乘除这种错误

![](https://gcy-1306312261.cos.ap-chengdu.myqcloud.com/blog/20230302100708.png)

就是因为，<font color=#dd0000 size=4>它本质上是一个语言模型</font>

就目前来讲，GPT 也经常会出现，大量编造答案的情况，也就是说，它本来都不知道它在说什么，但它就是在那给你硬扯

![](https://gcy-1306312261.cos.ap-chengdu.myqcloud.com/blog/20230302101901.png)

虽然现在它可能就是简单的模仿，但是当你模仿得，越来越像，越来越高级

99.9%的情况你都能回答正确的时候，那它到底是真的理解了，还是纯粹在那儿模仿，其实意义也不大了

这个其实也是图灵，早在图灵测试那篇论文里边，就讨论过的一个问题

与其我们问说， 机器能像人类一样思考吗 ，倒不如问说

<font color=#dd0000 size=4>机器能做人类做的事吗</font>
